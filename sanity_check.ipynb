{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ad895f4-b3e0-4d9e-86d5-9cbfcb85fa75",
   "metadata": {},
   "source": [
    "# Sanity Check: Local Inference\n",
    "\n",
    "You need to generate predictions so you can test the model.  Axolotl uploaded the trained model to\n",
    "\n",
    "[pbevan11/llama-3-8b-ocr-correction](https://huggingface.co/pbevan11/llama-3-8b-ocr-correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858e5904-d02f-43da-9e5d-304ac888c89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "badbb9aa143a4270a8b50e53c1854fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f82a194ddc418da20c0854d56b6cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7758628733f4928ba55a91a56d43061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4de647f40304fe8a1a6124cb5af99ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875547c4f43540c0a62e4ef6311b97f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/449 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "WARNING: BNB_CUDA_VERSION=118 environment variable detected; loading libbitsandbytes_cuda118.so.\n",
      "This can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH\n",
      "For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9a6f13ca184353972b88d92c040a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "model_id='pbevan11/llama-3-8b-ocr-correction' # this will be different for you based upon hub_model_id\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(model_id).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e487f417-b4f4-4fe2-a90a-2bb5ef7a98a6",
   "metadata": {},
   "source": [
    "### Prompt Template\n",
    "\n",
    "Next, we have to construct a prompt template that is as close as possible to the prompt template we saw earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddef1949-74c5-4806-963c-a9f831707109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(instruction, inp):\n",
    "    return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{inp}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "def prompt_tok(instruction, inp, return_ids=False):\n",
    "    _p = prompt(instruction, inp)\n",
    "    input_ids = tokenizer(_p, return_tensors=\"pt\", truncation=True).input_ids.cuda()\n",
    "    out_ids = model.generate(input_ids=input_ids, max_new_tokens=5000, \n",
    "                          do_sample=False)\n",
    "    ids = out_ids.detach().cpu().numpy()\n",
    "    if return_ids: return out_ids\n",
    "    \n",
    "    full_output = tokenizer.batch_decode(ids, skip_special_tokens=True)[0]\n",
    "    response_start = full_output.find(\"### Response:\")\n",
    "    if response_start != -1:\n",
    "        return full_output[response_start + len(\"### Response:\"):]\n",
    "    else:\n",
    "        return full_output[len(_p):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba7d50e-a089-4339-a9f0-528dbe287249",
   "metadata": {},
   "source": [
    "## Sanity Check Examples\n",
    "\n",
    "Next, we sanity check a few examples to make sure that:\n",
    "\n",
    "- Our prompt template is constructed correctly (indeed I made some mistakes at first!)\n",
    "- The model is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e07e75f9-a991-471d-aa85-1530cc88a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"You are an assistant that takes a piece of text that has been corrupted during OCR digitisation, and produce a corrected version of the same text.\"\n",
    "inp = \"Do Not Kule Oi't hy.er-l'rieed AjijqIi: imac - Analyst (fteuiers) Hcuiers - A | ) | ilf, <;/) in |) nter |iic . conic! deeiilf. l.o sell n lower-|)rieofl wersinn oi its Macintosh cornutor to nttinct ronsnnu-rs already euami'red ot its iPod music jiayo-r untl annoyoil. by sccnrit.y problems ivitJi Willtlows PCs , Piper.iaffray analyst. (Jcne Muster <aid on Tlinrtiday.\"\n",
    "\n",
    "inp2 = \"program * Turbine Build * the Buzz for 'Middle-Earth Online ' ( Reuteri ) Reutert - The people crammed into a.neeting room at the Providence Convention Center were.contemplating a long visit to an exotic land . They wanted to .know about the sbape of the mountain * and what the weather.would be like . They asked if the nativea would be approachable .\"\n",
    "\n",
    "# Try a historical one\n",
    "inp3 = \"\"\"\n",
    "jer'jl ~D. feritil°l England in het-comprehensive historic yet to make. ill From the sources above referred t° ;oerlTl the present undertaking toprovdlw, ~ biographical sketches for general real', 1 fro\" .added a few nomes ofrecent times, ta7ii, of of the church,_ as e.g. Nikon Fdtrio founder of \"The Christian Brothe'le`elia treated without 'any leaning to the fro P-4 practice which- they may exhibit'diSeloolrl°!tis the English Church, but simplY.,llo,e- terirk holiness and self4lenial whichiS4ll3_, j Ar`—•elpgii saint in all ages and conntriesi.ancl\"—AL of the series toeommemorate, rather'''. 01 tical rank or-social station. wad 11- Py'ff/1; Sermons and treatises en:rep-e-, pit thing like the same manner as' „ `,-9). person. Itio words can pourtrx,h'oe bly the size, and beautp,. aooeat 111,.0t Crystal Palace, as a picture.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33eeb326-b083-4cf3-a9f1-03dc408d2a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Do Not Rule Out Lower-Priced Mac - Analyst (Reuters) Reuters - Apple Inc.  may be considering a lower-priced version of its Macintosh computer to attract consumers already enamored of its iPod music player and annoyed by security problems with Windows PCs, PiperJaffray analyst Gene Munster said on Thursday.\n"
     ]
    }
   ],
   "source": [
    "out = prompt_tok(instruction, inp)\n",
    "print(out.replace('\\\\', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f3050d2-758f-45e1-add1-43d9e73bb257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Programs Turbine Builds the Buzz for 'Middle-Earth Online' (Reuters) Reuters - The people crammed into a meeting room at the Providence Convention Center were contemplating a long visit to an exotic land. They wanted to know about the shape of the mountains and what the weather would be like. They asked if the natives would be approachable.\n"
     ]
    }
   ],
   "source": [
    "out = prompt_tok(instruction, inp2)\n",
    "print(out.replace('\\\\', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb16faaa-180a-46da-9455-cd71a1253c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eremiah D. Farrell England in her-comprehensive historic yet to make. Ill From the sources above referred to, the present undertaking to provide, biographical sketches for general reading, from added a few names of recent times, such as of the church, as e.g. Nikon, founder of The Christian Brothers, treated without any leaning to the form of practice which they may exhibit in school, but simply to their holiness and self-denial which all saints in all ages and countries can and should emulate, and all of the series to commemorate rather than of technical rank or social station. His Sermons and treatises are replete with everything like the same manner as a person. His words can pour forth by the size, and beauty, as a picture.\n"
     ]
    }
   ],
   "source": [
    "out = prompt_tok(instruction, inp3)\n",
    "print(out.replace('\\\\', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e70980d-7abd-4987-92ab-452c315a14f0",
   "metadata": {},
   "source": [
    "## Homework - Token Check\n",
    "\n",
    "Optional Homework!  Check that there aren't any token issues https://hamel.dev/notes/llm/finetuning/05_tokenizer_gotchas.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee5d46-eb8a-4ffb-b805-5ed240c1c86e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
